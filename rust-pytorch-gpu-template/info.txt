d apps in rust-pytorch-gpu-template:   1. stress   2. rust-bert model (for direct consumption from rust cmd line)
2nd app requires: git clone https://github.com/guillaume-be/rust-bert.git  (bert model can be directly consumed w/ cargo cmd line)




@ntrajic ➜ /workspaces/rust-data-engineering/rust-pytorch-gpu-template (main) $ tree
.
├── cuda-11.7.sh
├── env.sh
├── hello-pytorch
│   ├── Cargo.toml
│   └── src
│       └── main.rs
├── install-libtorch.sh
├── LICENSE
├── load-mnist.sh
├── lyrics.txt
├── Makefile
├── mnist-cli-gpu
│   ├── Cargo.toml
│   ├── Makefile
│   └── src
│       ├── lib.rs
│       └── main.rs
├── model.pth
├── portable-pytorch
│   ├── Cargo.toml
│   ├── export.py
│   ├── Makefile
│   ├── README.md
│   ├── requirements.txt
│   └── src
│       ├── lib.rs
│       └── main.rs
├── post-install.sh
├── pytorch-cli
├── pytorch-gpu-util
│   ├── Cargo.toml
│   └── src
│       └── main.rs
├── pytorch-mnist
│   ├── Cargo.toml
│   ├── README.md
│   └── src
│       ├── main.rs
│       ├── mnist_conv.rs
│       ├── mnist_linear.rs
│       └── mnist_nn.rs
├── quickstart_pytorch.py
├── README.md
├── requirements.txt
├── setup.sh
├── stress
│   ├── Cargo.toml
│   ├── Makefile
│   └── src
│       ├── lib.rs
│       └── main.rs
├── translate
│   ├── Cargo.toml
│   ├── lyrics.txt
│   ├── Makefile
│   └── src
│       ├── lib.rs
│       └── main.rs
└── verify-PyTorch.py

@ntrajic ➜ /workspaces/rust-data-engineering (main) $ cd rust-pytorch-gpu-template/
@ntrajic ➜ /workspaces/rust-data-engineering/rust-pytorch-gpu-template (main) $ make install
python3 -m pip install --upgrade pip \
        && pip install -r requirements.txt
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pip in /home/vscode/.local/lib/python3.9/site-packages (23.3.2)
Collecting pip
  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)
Downloading pip-24.0-py3-none-any.whl (2.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 26.1 MB/s eta 0:00:00
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.3.2
    Uninstalling pip-23.3.2:
      Successfully uninstalled pip-23.3.2
Successfully installed pip-24.0
Defaulting to user installation because normal site-packages is not writeable
Collecting torch==1.13.1 (from -r requirements.txt (line 1))
  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 887.4/887.4 MB 1.8 MB/s eta 0:00:00
Collecting torchaudio==0.13.1 (from -r requirements.txt (line 2))
  Downloading torchaudio-0.13.1-cp39-cp39-manylinux1_x86_64.whl (4.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 48.0 MB/s eta 0:00:00
Collecting torchvision==0.14.1 (from -r requirements.txt (line 3))
  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 41.0 MB/s eta 0:00:00
Requirement already satisfied: typing-extensions in /home/vscode/.local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.9.0)
Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 1))
  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 18.8 MB/s eta 0:00:00
Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->-r requirements.txt (line 1))
  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 3.3 MB/s eta 0:00:00
Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->-r requirements.txt (line 1))
  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 5.0 MB/s eta 0:00:00
Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 1))
  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 40.2 MB/s eta 0:00:00
Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.9/site-packages (from torchvision==0.14.1->-r requirements.txt (line 3)) (1.26.3)
Requirement already satisfied: requests in /home/vscode/.local/lib/python3.9/site-packages (from torchvision==0.14.1->-r requirements.txt (line 3)) (2.31.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from torchvision==0.14.1->-r requirements.txt (line 3)) (10.2.0)
Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (52.0.0)
Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (0.34.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (3.6)
Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (2.1.0)
Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.9/site-packages (from requests->torchvision==0.14.1->-r requirements.txt (line 3)) (2023.11.17)
Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio


@ntrajic ➜ /workspaces/rust-data-engineering/rust-pytorch-gpu-template/stress (main) $ cargo update -p clap@4.5.0 --precise 4.0.32
    Updating crates.io index
    Removing anstream v0.6.11
    Removing anstyle v1.0.6
    Removing anstyle-parse v0.2.3
    Removing anstyle-query v1.0.2
    Removing anstyle-wincon v3.0.2
      Adding bitflags v1.3.2
      Adding bitflags v2.4.2
 Downgrading clap v4.5.0 -> v4.0.32
    Removing clap_builder v4.5.0
 Downgrading clap_derive v4.5.0 -> v4.0.21
 Downgrading clap_lex v0.7.0 -> v0.3.3
    Removing colorchoice v1.0.0
      Adding errno v0.3.8
      Adding hermit-abi v0.3.5
      Adding is-terminal v0.4.10
      Adding linux-raw-sys v0.4.13
      Adding os_str_bytes v6.6.1
      Adding proc-macro-error v1.0.4
      Adding proc-macro-error-attr v1.0.4
      Adding rustix v0.38.31
 Downgrading strsim v0.11.0 -> v0.10.0
      Adding syn v1.0.109
      Adding termcolor v1.4.1
    Removing utf8parse v0.2.1
      Adding winapi v0.3.9
      Adding winapi-i686-pc-windows-gnu v0.4.0
      Adding winapi-util v0.1.6
      Adding winapi-x86_64-pc-windows-gnu v0.4.0
@ntrajic ➜ /workspaces/rust-data-engineering/rust-pytorch-gpu-template/stress (main) $ make all
cargo fmt --quiet
cargo clippy --quiet
cargo test --quiet

running 0 tests

test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 0 tests

test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s


running 0 tests

test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s

cargo run 
   Compiling stress v0.1.0 (/workspaces/rust-data-engineering/rust-pytorch-gpu-template/stress)
    Finished dev [unoptimized + debuginfo] target(s) in 1.94s
     Running `target/debug/stress`


@ntrajic ➜ /workspaces/rust-data-engineering/rust-pytorch-gpu-template/stress (main) $ cargo run -- --help
    Finished dev [unoptimized + debuginfo] target(s) in 0.09s
     Running `target/debug/stress --help`
A Stress Test for PyTorch CPU and GPU.  There are three subcommands: cpu, gpu, and tgpu. The tgpu subcommand uses Rayon to send the load to the GPU.

Usage: stress [COMMAND]

Commands:
  cpu   
  gpu   
  tgpu  
  help  Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help information
  -V, --version  Print version information


in separate terminal watch the load with **htop**:


  1)  cargo run -- cpu <enter>

  2)  cargo run -- gpu <enter>

  3)  cargo run -- tgpu <enter>
